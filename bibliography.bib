@inproceedings{scythe,
  title        = {Synthesizing highly expressive SQL queries from input-output examples},
  author       = {Wang, Chenglong and Cheung, Alvin and Bodik, Rastislav},
  year         = 2017,
  booktitle    = {Proceedings of the 38th ACM SIGPLAN Conference on Programming Language Design and Implementation},
  location     = {Barcelona, Spain},
  publisher    = {Association for Computing Machinery},
  address      = {New York, NY, USA},
  series       = {PLDI 2017},
  pages        = {452–466},
  doi          = {10.1145/3062341.3062365},
  isbn         = 9781450349888,
  url          = {https://doi.org/10.1145/3062341.3062365},
  numpages     = 15,
  keywords     = {Program Synthesis, Query by Example, SQL}
}

@article{dail-sql,
  title        = {Text-to-SQL Empowered by Large Language Models: A Benchmark Evaluation},
  author       = {Gao, Dawei and Wang, Haibin and Li, Yaliang and Sun, Xiuyu and Qian, Yichen and Ding, Bolin and Zhou, Jingren},
  year         = 2024,
  month        = {may},
  journal      = {Proc. VLDB Endow.},
  publisher    = {VLDB Endowment},
  volume       = 17,
  number       = 5,
  pages        = {1132–1145},
  doi          = {10.14778/3641204.3641221},
  issn         = {2150-8097},
  url          = {https://doi.org/10.14778/3641204.3641221},
  issue_date   = {January 2024},
  numpages     = 14
}

@inproceedings{spider-sql,
  title        = {{S}pider: A Large-Scale Human-Labeled Dataset for Complex and Cross-Domain Semantic Parsing and Text-to-{SQL} Task},
  author       = {Yu, Tao  and Zhang, Rui  and Yang, Kai  and Yasunaga, Michihiro  and Wang, Dongxu  and Li, Zifan  and Ma, James  and Li, Irene  and Yao, Qingning  and Roman, Shanelle  and Zhang, Zilin  and Radev, Dragomir},
  year         = 2018,
  month        = {oct},
  booktitle    = {Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing},
  publisher    = {Association for Computational Linguistics},
  address      = {Brussels, Belgium},
  pages        = {3911--3921},
  doi          = {10.18653/v1/D18-1425},
  url          = {https://aclanthology.org/D18-1425},
  editor       = {Riloff, Ellen  and Chiang, David  and Hockenmaier, Julia  and Tsujii, Jun{'}ichi}
}

@article{patsql,
  title        = {PATSQL: efficient synthesis of SQL queries from example tables with quick inference of projected columns},
  author       = {Takenouchi, Keita and Ishio, Takashi and Okada, Joji and Sakata, Yuji},
  year         = 2021,
  month        = {jul},
  journal      = {Proc. VLDB Endow.},
  publisher    = {VLDB Endowment},
  volume       = 14,
  number       = 11,
  pages        = {1937–1949},
  doi          = {10.14778/3476249.3476253},
  issn         = {2150-8097},
  url          = {https://doi.org/10.14778/3476249.3476253},
  issue_date   = {July 2021},
  numpages     = 13
}

@misc{yang2024qwen2technicalreport,
      title={Qwen2 Technical Report},
      author={An Yang and Baosong Yang and Binyuan Hui and Bo Zheng and Bowen Yu and Chang Zhou and Chengpeng Li and Chengyuan Li and Dayiheng Liu and Fei Huang and Guanting Dong and Haoran Wei and Huan Lin and Jialong Tang and Jialin Wang and Jian Yang and Jianhong Tu and Jianwei Zhang and Jianxin Ma and Jianxin Yang and Jin Xu and Jingren Zhou and Jinze Bai and Jinzheng He and Junyang Lin and Kai Dang and Keming Lu and Keqin Chen and Kexin Yang and Mei Li and Mingfeng Xue and Na Ni and Pei Zhang and Peng Wang and Ru Peng and Rui Men and Ruize Gao and Runji Lin and Shijie Wang and Shuai Bai and Sinan Tan and Tianhang Zhu and Tianhao Li and Tianyu Liu and Wenbin Ge and Xiaodong Deng and Xiaohuan Zhou and Xingzhang Ren and Xinyu Zhang and Xipin Wei and Xuancheng Ren and Xuejing Liu and Yang Fan and Yang Yao and Yichang Zhang and Yu Wan and Yunfei Chu and Yuqiong Liu and Zeyu Cui and Zhenru Zhang and Zhifang Guo and Zhihao Fan},
      year={2024},
      eprint={2407.10671},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2407.10671},
}

@inproceedings{llm-enumerative-search,
  title        = {Guiding Enumerative Program Synthesis with Large Language Models},
  author       = {Li, Yixuan and Parsert, Julian and Polgreen, Elizabeth},
  year         = 2024,
  booktitle    = {Computer Aided Verification},
  publisher    = {Springer Nature Switzerland},
  address      = {Cham},
  pages        = {280--301},
  isbn         = {978-3-031-65630-9},
  editor       = {Gurfinkel, Arie and Ganesh, Vijay}
}

@inproceedings{probabilistic-model-synthesis,
  title        = {Accelerating search-based program synthesis using learned probabilistic models},
  author       = {Lee, Woosuk and Heo, Kihong and Alur, Rajeev and Naik, Mayur},
  year         = 2018,
  booktitle    = {Proceedings of the 39th ACM SIGPLAN Conference on Programming Language Design and Implementation},
  location     = {Philadelphia, PA, USA},
  publisher    = {Association for Computing Machinery},
  address      = {New York, NY, USA},
  series       = {PLDI 2018},
  pages        = {436–449},
  doi          = {10.1145/3192366.3192410},
  isbn         = 9781450356985,
  url          = {https://doi.org/10.1145/3192366.3192410},
  numpages     = 14,
  keywords     = {Domain-specific languages, Statistical methods, Synthesis, Transfer learning}
}

@inproceedings{ml-pbe,
  title        = {A machine learning framework for programming by example},
  author       = {Menon, Aditya Krishna and Tamuz, Omer and Gulwani, Sumit and Lampson, Butler and Kalai, Adam Tauman},
  year         = 2013,
  booktitle    = {Proceedings of the 30th International Conference on International Conference on Machine Learning - Volume 28},
  location     = {Atlanta, GA, USA},
  publisher    = {JMLR.org},
  series       = {ICML'13},
  pages        = {I–187–I–195},
  abstract     = {Learning programs is a timely and interesting challenge. In Programming by Example (PBE), a system attempts to infer a program from input and output examples alone, by searching for a composition of some set of base functions. We show how machine learning can be used to speed up this seemingly hopeless search problem, by learning weights that relate textual features describing the provided input-output examples to plausible sub-components of a program. This generic learning framework lets us address problems beyond the scope of earlier PBE systems. Experiments on a prototype implementation show that learning improves search and ranking on a variety of text processing tasks found on help forums.}
}

@inproceedings{llm-cegis,
  title        = {Counterexample Guided Inductive Synthesis Using Large Language Models and Satisfiability Solving},
  author       = {Jha, Sumit Kumar and Jha, Susmit and Lincoln, Patrick and Bastian, Nathaniel D. and Velasquez, Alvaro and Ewetz, Rickard and Neema, Sandeep},
  year         = 2023,
  booktitle    = {MILCOM 2023 - 2023 IEEE Military Communications Conference (MILCOM)},
  pages        = {944--949},
  doi          = {10.1109/MILCOM58377.2023.10356332},
  keywords     = {Military communication;Codes;Natural languages;Computer bugs;Syntactics;Planning;Task analysis}
}

@article{pipesql,
  title        = {SQL Has Problems. We Can Fix Them: Pipe Syntax In SQL},
  author       = {Shute, Jeff and Bales, Shannon and Brown, Matthew and Browne, Jean-Daniel and Dolphin, Brandon and Kudtarkar, Romit and Litvinov, Andrey and Ma, Jingchi and Morcos, John and Shen, Michael and Wilhite, David and Wu, Xi and Yu, Lulan},
  year         = 2024,
  month        = {nov},
  journal      = {Proc. VLDB Endow.},
  publisher    = {VLDB Endowment},
  volume       = 17,
  number       = 12,
  pages        = {4051–4063},
  doi          = {10.14778/3685800.3685826},
  issn         = {2150-8097},
  url          = {https://doi.org/10.14778/3685800.3685826},
  issue_date   = {August 2024},
  abstract     = {SQL has been extremely successful as the de facto standard language for working with data. Virtually all mainstream database-like systems use SQL as their primary query language. But SQL is an old language with significant design problems, making it difficult to learn, difficult to use, and difficult to extend. Many have observed these challenges with SQL, and proposed solutions involving new languages. New language adoption is a significant obstacle for users, and none of the potential replacements have been successful enough to displace SQL.In GoogleSQL, we've taken a different approach - solving SQL's problems by extending SQL. Inspired by a pattern that works well in other modern data languages, we added piped data flow syntax to SQL. The results are transformative - SQL becomes a flexible language that's easier to learn, use and extend, while still leveraging the existing SQL ecosystem and existing userbase. Improving SQL from within allows incrementally adopting new features, without migrations and without learning a new language, making this a more productive approach to improve on standard SQL.},
  numpages     = 13
}

@article{VeriEQL,
  title        = {VeriEQL: Bounded Equivalence Verification for Complex SQL Queries with Integrity Constraints},
  author       = {He, Yang and Zhao, Pinhan and Wang, Xinyu and Wang, Yuepeng},
  year         = 2024,
  month        = {apr},
  journal      = {Proc. ACM Program. Lang.},
  publisher    = {Association for Computing Machinery},
  address      = {New York, NY, USA},
  volume       = 8,
  number       = {OOPSLA1},
  doi          = {10.1145/3649849},
  url          = {https://doi.org/10.1145/3649849},
  issue_date   = {April 2024},
  abstract     = {The task of SQL query equivalence checking is important in various real-world applications (including query rewriting and automated grading) that involve complex queries with integrity constraints; yet, state-of-the-art techniques are very limited in their capability of reasoning about complex features (e.g., those that involve sorting, case statement, rich integrity constraints, etc.) in real-life queries. To the best of our knowledge, we propose the first SMT-based approach and its implementation, VeriEQL, capable of proving and disproving bounded equivalence of complex SQL queries. VeriEQL is based on a new logical encoding that models query semantics over symbolic tuples using the theory of integers with uninterpreted functions. It is simple yet highly practical -- our comprehensive evaluation on over 20,000 benchmarks shows that VeriEQL outperforms all state-of-the-art techniques by more than one order of magnitude in terms of the number of benchmarks that can be proved or disproved. VeriEQL can also generate counterexamples that facilitate many downstream tasks (such as finding serious bugs in systems like MySQL and Apache Calcite).},
  articleno    = 132,
  numpages     = 29,
  keywords     = {Equivalence Checking, Program Verification, Relational Databases}
}

@misc{bai2023qwentechnicalreport,
  title        = {Qwen Technical Report},
  author       = {Jinze Bai and Shuai Bai and Yunfei Chu and Zeyu Cui and Kai Dang and Xiaodong Deng and Yang Fan and Wenbin Ge and Yu Han and Fei Huang and Binyuan Hui and Luo Ji and Mei Li and Junyang Lin and Runji Lin and Dayiheng Liu and Gao Liu and Chengqiang Lu and Keming Lu and Jianxin Ma and Rui Men and Xingzhang Ren and Xuancheng Ren and Chuanqi Tan and Sinan Tan and Jianhong Tu and Peng Wang and Shijie Wang and Wei Wang and Shengguang Wu and Benfeng Xu and Jin Xu and An Yang and Hao Yang and Jian Yang and Shusheng Yang and Yang Yao and Bowen Yu and Hongyi Yuan and Zheng Yuan and Jianwei Zhang and Xingxuan Zhang and Yichang Zhang and Zhenru Zhang and Chang Zhou and Jingren Zhou and Xiaohuan Zhou and Tianhang Zhu},
  year         = 2023,
  url          = {https://arxiv.org/abs/2309.16609},
  eprint       = {2309.16609},
  archiveprefix = {arXiv},
  primaryclass = {cs.CL}
}

@misc{qu2024generationalignitnovel,
      title={Before Generation, Align it! A Novel and Effective Strategy for Mitigating Hallucinations in Text-to-SQL Generation},
      author={Ge Qu and Jinyang Li and Bowen Li and Bowen Qin and Nan Huo and Chenhao Ma and Reynold Cheng},
      year={2024},
      eprint={2405.15307},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2405.15307},
}

@article{chopchop,
author = {Nagy, Shaan and Zhou, Timothy and Polikarpova, Nadia and D'Antoni, Loris},
title = {ChopChop: A Programmable Framework for Semantically Constraining the Output of Language Models},
year = {2026},
issue_date = {January 2026},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {10},
number = {POPL},
url = {https://doi.org/10.1145/3776708},
doi = {10.1145/3776708},
abstract = {Language models (LMs) can generate code but cannot guarantee its correctness—often producing outputs that violate type safety, program invariants, or other semantic properties. Constrained decoding offers a solution by restricting generation to only produce programs that satisfy user-defined properties. However, existing methods are either limited to syntactic constraints or rely on brittle, ad hoc encodings of semantic properties over token sequences rather than program structure.    We present ChopChop, the first programmable framework for constraining the output of LMs with respect to semantic properties. ChopChop introduces a principled way to construct constrained decoders based on analyzing the space of programs a prefix represents. It formulates this analysis as a realizability problem which is solved via coinduction, connecting token-level generation with structural reasoning over programs. We demonstrate ChopChop's generality by using it to enforce (1) equivalence to a reference program and (2) type safety. Across a range of models and tasks, ChopChop improves success rates while maintaining practical decoding latency.},
journal = {Proc. ACM Program. Lang.},
month = jan,
articleno = {66},
numpages = {28},
keywords = {Coinduction, LLM, Semantic Constrained Decoding}
}

@misc{shen2025studyincontextlearningbasedtexttosqlerrors,
      title={A Study of In-Context-Learning-Based Text-to-SQL Errors},
      author={Jiawei Shen and Chengcheng Wan and Ruoyi Qiao and Jiazhen Zou and Hang Xu and Yuchen Shao and Yueling Zhang and Weikai Miao and Geguang Pu},
      year={2025},
      eprint={2501.09310},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2501.09310},
}

@article{typeConstrainedDecoding,
author = {M\"{u}ndler, Niels and He, Jingxuan and Wang, Hao and Sen, Koushik and Song, Dawn and Vechev, Martin},
title = {Type-Constrained Code Generation with Language Models},
year = {2025},
issue_date = {June 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {9},
number = {PLDI},
url = {https://doi.org/10.1145/3729274},
doi = {10.1145/3729274},
abstract = {Large language models (LLMs) have achieved notable success in code generation. However, they still frequently produce uncompilable output because their next-token inference procedure does not model formal aspects of code. Although constrained decoding is a promising approach to alleviate this issue, it has only been applied to handle either domain-specific languages or syntactic features of general-purpose programming languages. However, LLMs frequently generate code with typing errors, which are beyond the domain of syntax and generally hard to adequately constrain. To address this challenge, we introduce a type-constrained decoding approach that leverages type systems to guide code generation. For this purpose, we develop novel prefix automata and a search over inhabitable types, forming a sound approach to enforce well-typedness on LLM-generated code. We formalize our approach on a foundational simply-typed language and extend it to TypeScript to demonstrate practicality. Our evaluation on the HumanEval and MBPP datasets shows that our approach reduces compilation errors by more than half and significantly increases functional correctness in code synthesis, translation, and repair tasks across LLMs of various sizes and model families, including state-of-the-art open-weight models with more than 30B parameters. The results demonstrate the generality and effectiveness of our approach in constraining LLM code generation with formal rules of type systems.},
journal = {Proc. ACM Program. Lang.},
month = jun,
articleno = {171},
numpages = {26},
keywords = {Code Generation, Constrained Decoding, Language Model, Program Repair, Program Synthesis, Program Translation, Type System}
}

@inproceedings{scholak-etal-2021-picard,
    title = "{PICARD}: Parsing Incrementally for Constrained Auto-Regressive Decoding from Language Models",
    author = "Scholak, Torsten  and
      Schucher, Nathan  and
      Bahdanau, Dzmitry",
    editor = "Moens, Marie-Francine  and
      Huang, Xuanjing  and
      Specia, Lucia  and
      Yih, Scott Wen-tau",
    booktitle = "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2021",
    address = "Online and Punta Cana, Dominican Republic",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.emnlp-main.779/",
    doi = "10.18653/v1/2021.emnlp-main.779",
    pages = "9895--9901",
    abstract = "Large pre-trained language models for textual data have an unconstrained output space; at each decoding step, they can produce any of 10,000s of sub-word tokens. When fine-tuned to target constrained formal languages like SQL, these models often generate invalid code, rendering it unusable. We propose PICARD (code available at \url{https://github.com/ElementAI/picard}), a method for constraining auto-regressive decoders of language models through incremental parsing. PICARD helps to find valid output sequences by rejecting inadmissible tokens at each decoding step. On the challenging Spider and CoSQL text-to-SQL translation tasks, we show that PICARD transforms fine-tuned T5 models with passable performance into state-of-the-art solutions."
}

@misc{xiYan,
      title={XiYan-SQL: A Novel Multi-Generator Framework For Text-to-SQL},
      author={Yifu Liu and Yin Zhu and Yingqi Gao and Zhiling Luo and Xiaoxia Li and Xiaorong Shi and Yuntao Hong and Jinyang Gao and Yu Li and Bolin Ding and Jingren Zhou},
      year={2025},
      eprint={2507.04701},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2507.04701},
}

@article{constrained_sql,
author = {Ren, Tonghui and Ke, Chen and Fan, Yuankai and Jing, Yinan and He, Zhenying and Zhang, Kai and Wang, X. Sean},
title = {The Power of Constraints in Natural Language to SQL Translation},
year = {2025},
issue_date = {March 2025},
publisher = {VLDB Endowment},
volume = {18},
number = {7},
issn = {2150-8097},
url = {https://doi.org/10.14778/3734839.3734847},
doi = {10.14778/3734839.3734847},
abstract = {Current large language model (LLM)-based Natural Language to SQL (NL2SQL) approaches typically rely on the database schema and partial data values for the translation. These approaches are unable to use sufficient data for accurate database understanding due to limitations in data selection methods, and they cannot input the entire database due to the limited context window sizes of LLMs. This insufficient data integration may result in an incomplete understanding of the database, leading to semantically incorrect SQL generation. In this paper, we introduce REDSQL, a novel plug-and-play framework that refines the predicted SQL by utilizing the entire database in the refinement process. The core idea of REDSQL is to enhance SQL refinement by identifying potential errors based on the database content, which is achieved by applying constraints on the input relations of query operations. LLMs can refine the SQL using SQL-related information extracted by REDSQL, which provides concise and informative insights into the database. Additionally, REDSQL enhances schema semantics by integrating data profiling for more effective database utilization. Our experiments demonstrate that REDSQL consistently improves the performance of existing NL2SQL approaches across five benchmarks. Specifically, REDSQL elevates the accuracy of CODES to 67.3\% (+8.8\%) and PURPLE to 67.7\% (+11.1\%) on the Bird benchmark.},
journal = {Proc. VLDB Endow.},
month = mar,
pages = {2097–2111},
numpages = {15}
}

@inproceedings{arcadinho-etal-2022-t5ql,
    title = "{T}5{QL}: Taming language models for {SQL} generation",
    author = "Arcadinho, Samuel David  and
      Aparicio, David  and
      Veiga, Hugo  and
      Alegria, Antonio",
    editor = "Bosselut, Antoine  and
      Chandu, Khyathi  and
      Dhole, Kaustubh  and
      Gangal, Varun  and
      Gehrmann, Sebastian  and
      Jernite, Yacine  and
      Novikova, Jekaterina  and
      Perez-Beltrachini, Laura",
    booktitle = "Proceedings of the Second Workshop on Natural Language Generation, Evaluation, and Metrics (GEM)",
    month = dec,
    year = "2022",
    address = "Abu Dhabi, United Arab Emirates (Hybrid)",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.gem-1.23/",
    doi = "10.18653/v1/2022.gem-1.23",
    pages = "276--286",
    abstract = "Automatic SQL generation has been an active research area, aiming at streamlining the access to databases by writing natural language with the given intent instead of writing SQL. Current SOTA methods for semantic parsing depend on LLMs to achieve high predictive accuracy on benchmark datasets. This reduces their applicability, since LLMs requires expensive GPUs. Furthermore, SOTA methods are ungrounded and thus not guaranteed to always generate valid SQL. Here we propose T5QL, a new SQL generation method that improves the performance in benchmark datasets when using smaller LMs, namely T5-Base, by 13pp when compared against SOTA methods. Additionally, T5QL is guaranteed to always output valid SQL using a context-free grammar to constrain SQL generation. Finally, we show that dividing semantic parsing in two tasks, candidate SQLs generation and candidate re-ranking, is a promising research avenue that can reduce the need for large LMs."
}