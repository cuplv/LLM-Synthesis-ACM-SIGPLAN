\section{Related Work}
Prior research has explored SQL synthesis using classic approaches, such as enumerative search, to produce correct queries~\cite{scythe,patsql}.
These works focus on pruning the search space either through additional information provided by the user, such as the constants that are allowed to appear in a query~\cite{scythe,patsql}, or through pruning unproductive paths~\cite{scythe,patsql}.
They often include soundness and bounded completeness guarantees, but struggle to scale to larger, more complex queries.

Other research instead foregoes guarantees for empirical results.
Many recent works focus on leveraging Large Language Models (LLMs) to produce SQL queries~\cite{dail-sql}.
They have performed well empirically, reaching test suite accuracies of up to 86.6\%~\cite{dail-sql} against the Spider SQL dataset~\cite{spider-sql}. FIXME MiniSeek 91.2 but no reference

Some prior works build off the strengths of both approaches, using probabilistic models to guide search while verifying the correctness of produced candidates.
These prior works either require white-box access to probabilistic models~\cite{probabilistic-model-synthesis,ml-pbe}, or treat models as program candidate oracles~\cite{llm-cegis}, or apply a hybrid approach that combines both methods~\cite{llm-enumerative-search}.
However, all these works use probabilistic models to generate full candidate programs before evaluating them.
This leaves a large search space for the probabilistic model to categorize.

In contrast, we observe that LLMs are inherently next token predictors, rather than full sequence predictors.
We leverage this insight to guide LLM search using lexeme level guidance which provides early guidance for the LLM to avoid unproductive search paths.

With regards to ChopChop, A. our insights are complimentary to ChopChop 
B. they observed that once an LLM made a mistake...it was too late to go back and fix it...."The type system implemented in our semantic pruner will prevent
the assignment to divisors, but it will still allow line 2." so LLM commit to its solution so it is useful to mitigate these types of errors before it is too late
C. constrained decoding is known to skew the underlying distribution
D. The pruners in ChopChop seem a bit unrealistic to create but I guess this is theoretical
So ChopChop enforces semantic validity when generating queries...in theory...but this requires you to create pruners...and you still run into the issue of an LLM makes a mistake and you reach a point where its too late to correct it...so other symbolic fixes? I mean you could still use this...ChopChop still wouldn't work because the candidates aren't in top-k...you would need to have the model learn some more patterns/ clause constraints



