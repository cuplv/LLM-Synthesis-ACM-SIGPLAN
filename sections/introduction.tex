\section{Introduction}

\jedi{Problem: We consider studying the kinds of incremental prediction errors LLMs make that take them down the incorrect path in program synthesis tasks.}

\jedi{Why Important: LLMs are used for program synthesis, but errors can compound if the LLM starts off on the wrong track.} Large Language Models (LLMs) are increasingly used as program generators to synthesize working code from natural language prompts. In contrast to other program synthesis techniques, LLMs are scalable to larger and more complex programs; however, due to their autoregressive nature, they can get stuck down an incorrect path as \textit{incremental prediction errors} can propagate through the decoding process which ultimately produces invalid programs.

\jedi{In this paper we study the incremental errors LLMs make when synthesizing SQL queries. We categorize these mistakes to evaluate whether constrained decoding or other symbolic reasoning techniques an intervene during decoding and steer LLMs to correct queries.}

\jedi{LLMs predict queries token by token and constrained decoding enforces constraints at decoding time, so we focus our study on the incremental errors LLMs make.} Recent work in LLM-augmented program synthesis has explored decoding-time interventions, including constrained generation techniques \cite{chopchop}. Constrained decoding methods are typically evaluated only on fully generated queries; however, these techniques fundamentally operate at the token or lexeme level. 

% To understand the effectiveness of constrained decoding, we analyze the model's learned distribution for lexemes during decoding, since a constraint can only be enforced if the appropriate lexeme appears within the model’s top-k candidates.

\jedi{Existing SQL error taxonomies are based on fully generated queries, so we introduce a new taxonomy focusing on the incremental errors LLMs make.} For text-to-SQL, existing taxonomies analyze errors of fully generated queries \cite{qu2024generationalignitnovel}. SQL synthesis is particularly dependent on lexeme-level correctness. In addition to overall query structure, SQL queries are dependent on correct schema references and correct operator usage. In contrast to existing taxonomies, we propose a taxonomy of incremental lexeme-level errors made during decoding.

\jedi{A taxonomy of incremental SQL prediction errors then allows us to observe the potential benefit of symbolic repair and the limitations of constrained decoding for LLM-driven SQL synthesis.} We evaluate the ability of LLMs to synthesize correct SQL queries at the lexeme level and find that we can broadly categorize lexeme level errors into six categories.  We find that certain errors within these categories can be mitigated with simple symbolic fixes and constrained decoding. We also observe limitations of constrained decoding as these methods cannot correct errors if the correct lexeme is absent from the model’s top-k candidates.

\textbf{Contributions:}
\begin{itemize}
    \item We present a hierarchical taxonomy of error categorization for lexeme level LLM mistakes during the decoding process.
    \item We identify error categories that are amenable to symbolic repair and quantify an upper bound on repairable failures.
    % \item We introduce a constrained decoding methodology, \textit{schema constrained decoding} to address schema-based errors.
\end{itemize}
