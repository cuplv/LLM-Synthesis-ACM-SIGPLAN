\section{Conclusion}
LLMs are being increasingly used for program synthesis but solely relying on their probabilistic token ranking can lead to incorrect programs. In this work, we investigate these limitations and propose a lexeme level validation methodology to guide the LLM towards semantically valid queries. We find that many errors can be corrected by using a constraint decoding and beam-search guided reasoning technique to rerank the generated lexemes. For errors that cannot be corrected using these methods, purely symbolic techniques can be used to aid program synthesis.
