
\section{Our Approach}
Our overall system is shown in Figure \ref{fig:overview}.

\subsection{Language Model (LM) Generator}
Consider $\mathcal{L}$ to be an (autoregressive) Language Model created for a sequence generation task that has a predefined vocabulary $\Sigma$, consisting of some $k$ tokens which are used as part of the tokenization. At each timestep $i \in [1, n]$, the model generates a sequence of these tokens, $(t_1, t_2, \dots, t_n)$ based on an autoregressive decoding process where the token with the highest probability is selected. This is usually part of a heuristic or sampling based search procedure on the set of $k$ tokens to predict the next most probable token. Now, consider the LM to be finetuned on a new DSL and the tokens in the vocabulary are not changed. This means that the LM is now capable of producing the probability distribution over the same tokens but conforming to the changed ordering of our DSL $\ie$ if an original ordering of tokens $w \in \Sigma$ exists, then a new ordering of tokens $w^* \in \Sigma$ should also be produced by the LM. A $\mathcal{L}$ generates tokens and concatenates them by taking the token with the highest probability and generates a new token and continues until a whitespace token is generated or a max heap size is reached. 

\begin{exmp}\textit{
Consider the original token sequence $w = {\textit{SELECT, *, FROM, books}}$, drawn from SQL queries present in the model’s training data. Using our DSL, this sequence is transformed into $w^{*} = {\textit{PROJECT, *, FROM, books}}$. In this transformation, the only substituted token is $\textit{PROJECT}$, and we therefore expect the model’s vocabulary to assign a non-zero probability $p$ to this token.}

\textit{For commonly occurring words, we can fully expect the new word to also exist in the vocabulary, however, if the word does not exist we know that some $n$-gram combination of the word does exist. When for example the token, $\textit{REGENRATE} \notin \Sigma$ then we can form the same word by some combination like $\{\textit{RE, GEN, E, RATE}\} \in \Sigma$. In our approach, we use QWEN-7B~\cite{bai2023qwentechnicalreport}, which uses an open-source fast Byte Pair Encoding (BPE) for tokenization and $\text{len}(\Sigma) \in 151642$.
}\end{exmp}

Since we use the language model as an autoregressive next token predictor, we would also like to harness the power of the probabilistic nature in which the tokens are ranked. Usually, since the top-$1$ token is taken as the next prediction, there is an uncertainty that whether this next token is part of the valid query that satisfies the question that is requested by the user. Hence, we would also like to store, some top-$m$ tokens at each time step and perform a beam search when on these token sets when there is a mismatch in the token requested and the query validated.

\textbf{Language Model Validator}. With each generated lexeme, we validate the generated lexeme by evaluating it against the expected lexeme of the gold query. If the most probable lexeme does not match the gold lexeme, we consider it to be a mistake. We compare the generated lexeme with the gold lexeme while considering issues that arise with aliasing for column names by only considering the column name. For example $T1.BehaviorMonitoring$ and $BehaviorMonitoring$ would both be considered correct lexemes compared to the gold lexeme $BehaviorMonitoring$. If the top most probable lexeme does not match the gold lexeme, we guide the Language Model by correcting it with the gold lexeme and continue generating. We incrementally validate each generated lexeme to guide the Language Model towards more productive generation paths rather than allow it to fully generate a query before evaluating its correctness. 

% This \textbf{lexeme level validation} guides 

Our system architecture is outlined in Algorithm \ref{alg:system_alg}.

\begin{algorithm}[ht!]
    \caption{System Algorithm} 
    \begin{algorithmic}[1]
        \State \textbf{Require:} Language Model $\mathcal{L}$, beam width $m$, gold query $g$ and some string prompt $\mathcal{P}$, number of mistakes $n$
        \Procedure{LanguageModelValidator}{$\mathcal{P}, w, g, n $}
            \If{$g == w \text{~returns~} \mathrm{TRUE}$ }
                % \State $t_i \gets q ~||~ w$
                \State $\mathcal{P} \gets \mathcal{P} ~||~ w$
                \State \textbf{return} $\mathcal{P}, n$
            \Else
                % \State $t_i \gets q ~||~ g$
                \State $\mathcal{P} \gets \mathcal{P} ~||~ g$
                \State $n \gets n +1$
                
                \State \textbf{return} $\mathcal{P}, n$
            \EndIf
        \EndProcedure

    \Procedure{Orchestrator}{}
    \State ${n} \gets 0$
	\For {$i=1,2,\ldots,len(gold\_query)$}
		
        \State ${w_i} \gets $\Call{$\mathcal{L}$}{$\mathcal{P}$}
        \State ${g_i} \gets $\Call{GoldLexeme}{$g, i$} 
        % \State $B_i \in \{w_i^1,\dots,w_i^k\} $ which are the top k lexemes in a beam 
            
        \State $\mathcal{P}, n \gets $\Call{LanguageModelValidator}{$\mathcal{P}, w_i, g_i, n$} 
        
	\EndFor
    \State \textbf{return} $n$
    \EndProcedure
    \end{algorithmic} \label{alg:system_alg}
\end{algorithm}
