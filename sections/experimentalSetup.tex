\section{Experimental Setup}

\subsection{Implementation}

The system is implemented in Python using open source models FIXME and FIXME. We consider a lexeme to be complete if the next generated token is whitespace.

\subsection{Results}
Our empirical evaluation results are presented in Table FIXME.

% \begin{table}[]
% \begin{tabular}{rr}
% \multicolumn{1}{l}{}     & \multicolumn{1}{l}{Count} \\ \hline
% Total Number of Queries  & 30                        \\
% Total Number of Mistakes & 112                       \\
% Gold Lexeme Found in Top-k           & 70                        \\
% Gold Lexeme Not Found in Top-k       & 42                                          
% \end{tabular}
% \begin{tabular}{l l}
% \hline
% Total Not Found errors & 41 \\
% Gold was TSQL keyword & 23 \\
% Gold was NOT TSQL keyword & 18 \\
% \hline
% \end{tabular}
% \caption{This table shows the empirical evaluation results of our LLM guided program synthesis approach. We tested against 30 queries. Across these 30 queries, the LLM made 112 mistakes. Of these mistakes, 70 of them were recoverable as they were generated by the LLM and stored in the top-k beam. Forty-two mistakes were not recoverable.}
% \label{eval1}
% \end{table}


% \begin{table}[]
% \begin{tabular}{l l}
% \hline
% Total Number of Queries & 30 \\
% Total Number of Mistakes & 200 \\
% Gold Lexeme Found in Top-k & 77 \\
% Gold Lexeme Not Found in Top-k & 123 \\
% \hline
% \end{tabular}
% \begin{tabular}{l l}
% \hline
% Total Not Found errors & 117 \\
% Gold was SQL keyword & 16 \\
% Gold was NOT SQL keyword & 101 \\
% \hline
% \end{tabular}

% \caption{This table shows the empirical evaluation results for SQL generation. Mostly schema and aggregation errors. For the finetuned model eglym/DR-TEXT2SQL-CodeLlama2-7B }
% \label{eval1}
% \end{table}

% \begin{table}[]
% \begin{tabular}{l l}
% \hline
% Total Number of Queries & 30 \\
% Total Number of Mistakes & 276 \\
% % Gold Lexeme Found in Top-k & 77 \\
% % Gold Lexeme Not Found in Top-k & 123 \\

% \hline
% \end{tabular}
% \begin{tabular}{l l}
% \hline
% Total Not Found errors & 234 \\
% Gold was SQL keyword & 51 \\
% Gold was NOT SQL keyword & 183 \\
% \hline
% \end{tabular}

% \caption{Results for Qwen2.5-Coder-7B }
% \label{eval1}
% \end{table}

% SFT model - XiYanSQL-QwenCoder-7B-2504

% \begin{table*}[]
% \begin{tabular}{rrl}
% \hline
% \multicolumn{1}{l}{Type of Error} & \multicolumn{1}{l}{Rough Distribution} & Suggested Symbolic Fix \\ \hline
% \begin{tabular}[c]{@{}r@{}}Schema Mismatch\\ (also join on wrong column \\ errors could also go here)\end{tabular} & 50-70\% of errors & \begin{tabular}[c]{@{}l@{}}top-k: schema based decoding\\ usually the highest ranked schema element is gold\\ not in top-k: have the LLM rank schema elements\end{tabular} \\ \hline
% Structural & 10-20\% & \begin{tabular}[c]{@{}l@{}}easy: end of a query determine if you need a LIMIT \\ medium: \\ hard: catch all\end{tabular} \\ \hline
% WHERE &  &  \\ \hline
% Aggregates &  &  \\ \hline
% Other &  &  \\ \hline
% \end{tabular}
% \caption{Error Types and suggested symbolic fixes }
% \end{table*}

% \begin{table*}[]
% \begin{tabular}{|l|l|l|l|}
% \hline
%  & \begin{tabular}[c]{@{}l@{}}XGenerationLab/\\ XiYanSQL-QwenCoder-14B-2504\end{tabular} & \begin{tabular}[c]{@{}l@{}}XGenerationLab/\\ XiYanSQL-QwenCoder-7B-2504\end{tabular} & \begin{tabular}[c]{@{}l@{}}eglym/\\ DR-TEXT2SQL-CodeLlama2-7B\end{tabular} \\ \hline
% Schema (includes join) & 214 & 211 & 206 \\ \hline
% Structural & 31 & 45 & 32 \\ \hline
% \begin{tabular}[c]{@{}l@{}}Where \\ (note these \\ numbers are inflated)\end{tabular} & 22 & 24 & 19 \\ \hline
% Aggregate & 20 & 21 & 11 \\ \hline
% Other & 30 & 17 & 17 \\ \hline
% Total Errors & 318 & 318 & 285 \\ \hline
% \end{tabular}
% \caption{Different SFT models and general error distributions over 51 queries.}
% \end{table*}