%%%% kr-instructions.tex -- version 1.3 (11-Jan-2021)

\typeout{KR2026 Instructions for Authors}

% These are the instructions for authors for KR-26.

\documentclass{article}
\pdfpagewidth=8.5in
\pdfpageheight=11in

\usepackage{kr}

% Use the postscript times font!
\usepackage{times}
\usepackage{soul}
\usepackage{url}
\usepackage[hidelinks]{hyperref}
\usepackage[utf8]{inputenc}
\usepackage[small]{caption}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{booktabs}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{ifthen}
\usepackage{xcolor}

\newcommand\algorithmicprocedure{\textbf{procedure}}
\newcommand{\algorithmicendprocedure}{\algorithmicend\ \algorithmicprocedure}
\makeatletter
\newcommand\PROCEDURE[3][default]{%
  \ALC@it
  \algorithmicprocedure\ \textsc{#2}(#3)%
  \ALC@com{#1}%
  \begin{ALC@prc}%
}
\newcommand\ENDPROCEDURE{%
  \end{ALC@prc}%
  \ifthenelse{\boolean{ALC@noend}}{}{%
    \ALC@it\algorithmicendprocedure
  }%
}
\newcommand\CALL[2]{\textsc{#1}(#2)}
\newenvironment{ALC@prc}{\begin{ALC@g}}{\end{ALC@g}}
\makeatother

\urlstyle{same}

% the following package is optional:
%\usepackage{latexsym}

% See https://www.overleaf.com/learn/latex/theorems_and_proofs
% for a nice explanation of how to define new theorems, but keep
% in mind that the amsthm package is already included in this
% template and that you must *not* alter the styling.
\newtheorem{example}{Example}
\newtheorem{theorem}{Theorem}

% Following comment is from ijcai97-submit.tex:
% The preparation of these files was supported by Schlumberger Palo Alto
% Research, AT\&T Bell Laboratories, and Morgan Kaufmann Publishers.
% Shirley Jowell, of Morgan Kaufmann Publishers, and Peter F.
% Patel-Schneider, of AT\&T Bell Laboratories collaborated on their
% preparation.

% These instructions can be modified and used in other conferences as long
% as credit to the authors and supporting agencies is retained, this notice
% is not changed, and further modification or reuse is not restricted.
% Neither Shirley Jowell nor Peter F. Patel-Schneider can be listed as
% contacts for providing assistance without their prior permission.

% To use for other conferences, change references to files and the
% conference appropriate and use other authors, contacts, publishers, and
% organizations.
% Also change the deadline and address for returning papers and the length and
% page charge instructions.
% Put where the files are available in the appropriate places.
%PDF Info Is REQUIRED.
\pdfinfo{
/TemplateVersion (KR.2026.0)
}



\title{Lexeme Level Verification for Language Model Guided Program Synthesis}
\input{commands}

% Single author syntax
\iffalse % (remove the multiple-author syntax below and \iffalse ... \fi here)
\author{%
    Author name
    \affiliations
    Affiliation
    \emails
    email@example.com    % email
}
\fi
% Multiple author syntax
\author{%
First Author$^1$\and
Second Author$^2$\and
Third Author$^{2,3}$\and
Fourth Author$^4$ \\
\affiliations
$^1$First Affiliation\\
$^2$Second Affiliation\\
$^3$Third Affiliation\\
$^4$Fourth Affiliation \\
\emails
\{first, second\}@example.com,
third@other.example.com,
fourth@example.com
}

\begin{document}

\maketitle

\begin{abstract}

Large Language Models (LLMs) exhibit strong performance for program synthesis tasks including text-to-SQL, up to 86.6\% accuracy on the Spider 1.0 benchmark, but purely neural techniques remain prone to hallucinations.
Existing symbolic approaches to improve accuracy on program synthesis tasks generally rely on post-hoc verification, which fails to constrain unproductive path exploration, or constrained decoding techniques that rely on learned distributions leaning towards correct programs.
In this work, we study the mistakes LLMs make when synthesizing SQL queries.
We observe that errors can be grouped into five error categories, two of which can be addressed by simple symbolic fixes.
Importantly, we find that \emph{constrained decoding alone is insufficient} to address \wip{<z>} of these categories.
Our findings provide interpretable insight into where LLMs fail and suggest promising, neuro-symbolic directions for improving LLM guided program synthesis.

FIXME finetuning would solve some categories?
% include limitations of constrained decoding 

Large Language Models (LLMs) have exhibited strong performance on program synthesis tasks such as text-to-SQL, achieving up to 87\% accuracy on state-of-the-art challenges such as the Yale Semantic Parsing (Spider). However, most of the top-performing methods bridge the semantic gap between natural language and SQL using clever prompt engineering or in-context learning techniques. 

\end{abstract}

\begin{figure*}
    \centering
    \includegraphics[width=\textwidth]{Systemoverview.png}
    \caption{The overall system architecture. The Language Model Generator is prompted to generate a TSQL query given a database schema and natural language question. The generator returns a list of lexemes to the Validator which incrementally validates the most probable lexeme against the gold one and corrects the generator if there is a mismatch.}
    \label{fig:overview}
\end{figure*}

\input{sections/introduction}

\input{sections/related_work}

% \section{TSQL}
% \input{sections/syntax}

% \input{sections/semantics}

\input{sections/approach}

\input{sections/experimentalSetup}

\input{sections/conclusion}


%% The file kr.bst is a bibliography style file for BibTeX 0.99c
\bibliographystyle{kr}
\bibliography{sample-base}

\end{document}


